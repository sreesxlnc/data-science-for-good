{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization As A Service (OPTaaS)\n",
    "\n",
    "In this notebook, we test out Mind Foundry's OPTimization as a Service (OPTaaS) capabilities. We'll use OPTaaS to try and optimize the hyperparameters of a gradient boosting machine for a supervised multiclass machine learning problem. This set of features was created using automated feature engineering in Featuretools on the data science for good Costa Rican Household poverty prediction competition dataset.\n",
    "\n",
    "## Roadmap\n",
    "\n",
    "1. Load in Data\n",
    "    * Dataset has already been formatted\n",
    "2. Define objective function for optimization\n",
    "    * Optimization function takes in hyperparameters and returns a score\n",
    "    * 5 fold cross validation Macro F1 Score of a gradient boosting machine\n",
    "    * Write a custom scorer for Light GBM \n",
    "3. Define search space for OPTaaS\n",
    "    * Set up hyperparameter distributions\n",
    "4. Create a task\n",
    "    * Goal is to maximize score\n",
    "    * Add parameters and constraint(s)\n",
    "5. Run optimization\n",
    "    * Currently using 100 iterations\n",
    "    * Option for resuming task with saved results\n",
    "6. Inspect results\n",
    "\n",
    "These results will be compared to Bayesian Optimization using Hyperopt and SMAC (coming soon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Evaluation of the model\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data \n",
    "\n",
    "This set of features was created using automated feature engineering in Featuretools. The original dataset is part of the Costa Rican Household poverty prediction competition where the objective is to predict poverty at a household level given individual and household information. This is a supervised multiclass machine learning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willk\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (572) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10307, 2016)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv('data/ft_2000_important.csv')\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_base = pd.read_csv('data/test.csv')[['Id', 'idhogar']]\n",
    "\n",
    "# Separate out training and testing\n",
    "train = features[features['Target'].notnull()].copy()\n",
    "test = features[features['Target'].isnull()].copy()\n",
    "\n",
    "train_labels = np.array(train.pop('Target'))\n",
    "test_ids = list(test.pop('idhogar'))\n",
    "\n",
    "train, test = train.align(test, join = 'inner', axis = 1)\n",
    "\n",
    "# Deal with data type issues\n",
    "for c in train:\n",
    "    if train[c].dtype == 'object':\n",
    "        train[c] = train[c].astype(np.float32)\n",
    "        test[c] = test[c].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure all the data is numeric (as it should be)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train objects:  Index([], dtype='object')\n",
      "Test objects:  Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('Train objects: ', train.columns[np.where(train.dtypes == 'object')])\n",
    "print('Test objects: ', test.columns[np.where(test.dtypes == 'object')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks good with the data. Next we'll import the required mindfoundry methods. You'll need to use your own API key! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindfoundry.optaas.client.client import OPTaaSClient, Goal\n",
    "from mindfoundry.optaas.client.parameter import (Distribution, CategoricalParameter,\n",
    "                                                 IntParameter, ChoiceParameter, \n",
    "                                                 NumericParameter, FloatParameter)\n",
    "\n",
    "from mindfoundry.optaas.client.constraint import Constraint\n",
    "\n",
    "# Read api key\n",
    "with open('C:/Users/willk/OneDrive/Desktop/optaas_key.txt', 'r') as f:\n",
    "    api_key = str(f.read())\n",
    "    \n",
    "# Set up a client \n",
    "client = OPTaaSClient('https://optaas.mindfoundry.ai', api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective Function\n",
    "\n",
    "The objective function takes in hyperparameters and returns a score to maximize (or minimize). For this problem, the metric is Macro F1 score over the four classes. We first write a custom evaluation metric for the Light GBM, and then an objective function that returns a 5 fold cross validation Macro F1 score for a given set of hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1_score(labels, predictions):\n",
    "    \"\"\"Custom Macro F1 Score for Light GBM\"\"\"\n",
    "    \n",
    "    # Reshape the predictions as needed\n",
    "    predictions = predictions.reshape(len(np.unique(labels)), -1 ).argmax(axis = 0)\n",
    "    \n",
    "    metric_value = f1_score(labels, predictions, average = 'macro')\n",
    "    \n",
    "    # Return is name, value, is_higher_better\n",
    "    return 'macro_f1', metric_value, True\n",
    "\n",
    "def objective(num_leaves, learning_rate, boosting_type,\n",
    "                      subsample, subsample_for_bin, min_child_samples,\n",
    "                      reg_alpha, reg_lambda, colsample_bytree, nfolds=5):\n",
    "    \"\"\"Return validation score from hyperparameters for LightGBM\"\"\"\n",
    "\n",
    "    # Using stratified kfold cross validation\n",
    "    strkfold = StratifiedKFold(n_splits = nfolds, shuffle = True)\n",
    "    \n",
    "    # Convert to arrays for indexing\n",
    "    features = np.array(train)\n",
    "    labels = np.array(train_labels).reshape((-1 ))\n",
    "    \n",
    "    valid_scores = []\n",
    "    best_estimators = []\n",
    "    \n",
    "    # Create model with hyperparameters\n",
    "    model = lgb.LGBMClassifier(num_leaves=num_leaves, learning_rate=learning_rate,\n",
    "                               boosting_type=boosting_type, subsample=subsample,\n",
    "                               subsample_for_bin=subsample_for_bin, \n",
    "                               min_child_samples=min_child_samples,\n",
    "                               reg_alpha=reg_alpha, reg_lambda=reg_lambda, \n",
    "                               colsample_bytree=colsample_bytree,\n",
    "                               class_weight = 'balanced',\n",
    "                               n_jobs=-1, n_estimators=10000)\n",
    "    \n",
    "    # Iterate through the folds\n",
    "    for i, (train_indices, valid_indices) in enumerate(strkfold.split(features, labels)):\n",
    "        \n",
    "        # Training and validation data\n",
    "        X_train = features[train_indices]\n",
    "        X_valid = features[valid_indices]\n",
    "        y_train = labels[train_indices]\n",
    "        y_valid = labels[valid_indices]\n",
    "        \n",
    "        # Train with early stopping\n",
    "        model.fit(X_train, y_train, early_stopping_rounds = 100, \n",
    "                  eval_metric = macro_f1_score,\n",
    "                  eval_set = [(X_train, y_train), (X_valid, y_valid)],\n",
    "                  eval_names = ['train', 'valid'],\n",
    "                  verbose = -1)\n",
    "        \n",
    "        # Record the validation fold score\n",
    "        valid_scores.append(model.best_score_['valid']['macro_f1'])\n",
    "        best_estimators.append(model.best_iteration_)\n",
    "        \n",
    "    best_estimators = np.array(best_estimators)\n",
    "    valid_scores = np.array(valid_scores)\n",
    "    \n",
    "#     return valid_scores, best_estimators\n",
    "\n",
    "    # Write to the csv file ('a' means append)\n",
    "#     of_connection = open(OUT_FILE, 'a')\n",
    "#     writer = csv.writer(of_connection)\n",
    "#     writer.writerow([loss, hyperparameters, ITERATION, run_time, best_score, best_std])\n",
    "#     of_connection.close()\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "#     return {'loss': loss, 'hyperparameters': hyperparameters, 'iteration': ITERATION,\n",
    "#             'train_time': run_time, 'status': STATUS_OK}\n",
    "\n",
    "    return valid_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "Next we define the hyperparameter distributions. I haven't figured out everything about the library and service, but I tried to recreate hyperparameter distributions I've used for both random search and bayesian optimization in Hyperopt. The `learning_rate` is a log normal, and the `subsample` will depend on the `boosting_type` as we'll see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_type = CategoricalParameter('boosting_type', \n",
    "                                     values = ['gbdt', 'dart', 'goss'], \n",
    "                                     id='boosting_type')\n",
    "\n",
    "num_leaves = IntParameter('num_leaves', minimum=3, \n",
    "                          maximum=50, id='num_leaves')\n",
    "\n",
    "learning_rate = FloatParameter('learning_rate', minimum=0.025, \n",
    "                               maximum=0.25, id='learning_rate',\n",
    "                               distribution=Distribution.LOGUNIFORM)\n",
    "\n",
    "subsample = FloatParameter('subsample', minimum=0.5, \n",
    "                           maximum=1.0, id='subsample')\n",
    "\n",
    "subsample_for_bin = IntParameter('subsample_for_bin', minimum=2000, \n",
    "                                 maximum=100000, id='subsample_for_bin')\n",
    "\n",
    "min_child_samples = IntParameter('min_child_samples', minimum=5, \n",
    "                                 maximum=80, id='min_child_samples')\n",
    "\n",
    "reg_alpha = FloatParameter('reg_alpha', minimum=0.0, \n",
    "                           maximum=1.0, id='reg_alpha')\n",
    "\n",
    "reg_lambda = FloatParameter('reg_lambda', minimum=0.0, \n",
    "                            maximum=1.0, id='reg_lambda')\n",
    "\n",
    "colsample_bytree = FloatParameter('colsample_bytree', minimum=0.5, \n",
    "                                  maximum=1.0, id='colsample_bytree')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Task\n",
    "\n",
    "We can use these hyperparameters to create a task for OPTaaS. The constraint makes sure that `subsample = 1` when `boosting_type = \"goss\"`. This is necessary because \"goss\" cannot use subsampling. Everything else is straighforward, and we want to maximize the Macro F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "task = client.create_task(\n",
    "        title = 'Light GBM Opt',\n",
    "        goal = Goal.max,\n",
    "        parameters = [num_leaves, learning_rate, boosting_type,\n",
    "                      subsample, subsample_for_bin, min_child_samples,\n",
    "                      reg_alpha, reg_lambda, colsample_bytree],\n",
    "         constraints = [ Constraint(when=boosting_type=='goss', \n",
    "                                    then=subsample==1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Optimization\n",
    "\n",
    "The last step is to run optimization. We'll start with 100 iterations. The `%%capture` magic makes sure that we don't see all the LightGBM output (which cannot be surpressed) but it also means we can't see the optimization information from OPTaaS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "best_result, best_configuration = task.run(objective, max_iterations = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Results\n",
    "\n",
    "After 100 iterations, how did the optimization do? We can get the `best_configuration` and `best_score` pretty easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ 'id': '132dc8d6-bab1-4695-b058-6fcbdbf21684',\n",
       "  'type': 'exploitation',\n",
       "  'values': { 'boosting_type': 'dart',\n",
       "              'colsample_bytree': 0.9843467236959204,\n",
       "              'learning_rate': 0.11598629586769524,\n",
       "              'min_child_samples': 44,\n",
       "              'num_leaves': 49,\n",
       "              'reg_alpha': 0.35397370408131534,\n",
       "              'reg_lambda': 0.5904910774606467,\n",
       "              'subsample': 0.6299872254632797,\n",
       "              'subsample_for_bin': 60611}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ 'configuration': '132dc8d6-bab1-4695-b058-6fcbdbf21684',\n",
       "  'id': 3250,\n",
       "  'score': 0.4629755551376399,\n",
       "  'user_defined_data': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we can use these results to build a final model and make predictions on the test data. It would also be a good idea to examine the entire results so we can see where the best hyperparameter values concentrated. \n",
    "\n",
    "We'll save all the results for inspection. These can also be used to start optimization from 100 iterations rather than from a new task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Results into a Dataframe\n",
    "\n",
    "Of course we need our results in a dataframe, the data structure of choice for data scientists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = task.get_configurations()\n",
    "with open('configurations.txt', 'w') as f:\n",
    "    f.write(str(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = task.get_results()\n",
    "with open('results.txt', 'w') as f:\n",
    "    f.write(str(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ 'id': '8b0bc65b-3e9c-4b93-a9b2-ef108ed152e8',\n",
       "  'type': 'default',\n",
       "  'values': { 'boosting_type': 'gbdt',\n",
       "              'colsample_bytree': 0.75,\n",
       "              'learning_rate': 0.1375,\n",
       "              'min_child_samples': 42,\n",
       "              'num_leaves': 26,\n",
       "              'reg_alpha': 0.5,\n",
       "              'reg_lambda': 0.5,\n",
       "              'subsample': 0.75,\n",
       "              'subsample_for_bin': 51000}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ 'configuration': '8b0bc65b-3e9c-4b93-a9b2-ef108ed152e8',\n",
       "  'id': 3208,\n",
       "  'score': 0.44335890144866374,\n",
       "  'user_defined_data': None}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = pd.DataFrame(columns = [x for x in c[0].values.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'colsample_bytree': 0.75,\n",
       " 'learning_rate': 0.1375,\n",
       " 'min_child_samples': 42,\n",
       " 'num_leaves': 26,\n",
       " 'reg_alpha': 0.5,\n",
       " 'reg_lambda': 0.5,\n",
       " 'subsample': 0.75,\n",
       " 'subsample_for_bin': 51000}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for results in c:\n",
    "    id_ = results.id\n",
    "    ids.append(id_)\n",
    "    \n",
    "    hyp_dict = results.values\n",
    "    config = config.append(pd.DataFrame(hyp_dict, index = [0]), \n",
    "                           ignore_index = True)\n",
    "    \n",
    "config['config_id'] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dabd3954-3699-47f7-b788-5040d6c543e4\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for id_ in config['config_id']:\n",
    "    found = False\n",
    "    for results in r:\n",
    "        if results.configuration == id_:\n",
    "            scores.append(results.score)\n",
    "            found = True\n",
    "            \n",
    "    if not found:\n",
    "        print(id_)\n",
    "# config['score'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>boosting_type</th>\n",
       "      <th>subsample</th>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>config_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>51000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>8b0bc65b-3e9c-4b93-a9b2-ef108ed152e8</td>\n",
       "      <td>0.443359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>0.066103</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.959100</td>\n",
       "      <td>34856</td>\n",
       "      <td>11</td>\n",
       "      <td>0.671155</td>\n",
       "      <td>0.990424</td>\n",
       "      <td>0.826631</td>\n",
       "      <td>e0a3e3b8-4dd6-426c-afed-65b3991bc9bb</td>\n",
       "      <td>0.435779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>0.039836</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.625744</td>\n",
       "      <td>71666</td>\n",
       "      <td>49</td>\n",
       "      <td>0.451237</td>\n",
       "      <td>0.378928</td>\n",
       "      <td>0.588920</td>\n",
       "      <td>06f46a30-c8e7-4467-bf5f-d4fcde9e2b0c</td>\n",
       "      <td>0.440514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>0.075335</td>\n",
       "      <td>dart</td>\n",
       "      <td>0.987832</td>\n",
       "      <td>93713</td>\n",
       "      <td>72</td>\n",
       "      <td>0.973434</td>\n",
       "      <td>0.927150</td>\n",
       "      <td>0.609935</td>\n",
       "      <td>133ada9b-896a-4dbb-ada9-5c0777ee9cf4</td>\n",
       "      <td>0.440388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0.132886</td>\n",
       "      <td>dart</td>\n",
       "      <td>0.847583</td>\n",
       "      <td>45135</td>\n",
       "      <td>47</td>\n",
       "      <td>0.713148</td>\n",
       "      <td>0.197536</td>\n",
       "      <td>0.708709</td>\n",
       "      <td>c5d6b6e1-52be-432a-8694-c577e71709db</td>\n",
       "      <td>0.442698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  num_leaves  learning_rate boosting_type  subsample subsample_for_bin  \\\n",
       "0         26       0.137500          gbdt   0.750000             51000   \n",
       "1         41       0.066103          gbdt   0.959100             34856   \n",
       "2         34       0.039836          gbdt   0.625744             71666   \n",
       "3         44       0.075335          dart   0.987832             93713   \n",
       "4         41       0.132886          dart   0.847583             45135   \n",
       "\n",
       "  min_child_samples  reg_alpha  reg_lambda  colsample_bytree  \\\n",
       "0                42   0.500000    0.500000          0.750000   \n",
       "1                11   0.671155    0.990424          0.826631   \n",
       "2                49   0.451237    0.378928          0.588920   \n",
       "3                72   0.973434    0.927150          0.609935   \n",
       "4                47   0.713148    0.197536          0.708709   \n",
       "\n",
       "                              config_id     score  \n",
       "0  8b0bc65b-3e9c-4b93-a9b2-ef108ed152e8  0.443359  \n",
       "1  e0a3e3b8-4dd6-426c-afed-65b3991bc9bb  0.435779  \n",
       "2  06f46a30-c8e7-4467-bf5f-d4fcde9e2b0c  0.440514  \n",
       "3  133ada9b-896a-4dbb-ada9-5c0777ee9cf4  0.440388  \n",
       "4  c5d6b6e1-52be-432a-8694-c577e71709db  0.442698  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = config[~(config['config_id'] == 'dabd3954-3699-47f7-b788-5040d6c543e4')]\n",
    "config['score'] = scores\n",
    "config.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>boosting_type</th>\n",
       "      <th>subsample</th>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>config_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>49</td>\n",
       "      <td>0.115986</td>\n",
       "      <td>dart</td>\n",
       "      <td>0.629987</td>\n",
       "      <td>60611</td>\n",
       "      <td>44</td>\n",
       "      <td>0.353974</td>\n",
       "      <td>0.590491</td>\n",
       "      <td>0.984347</td>\n",
       "      <td>132dc8d6-bab1-4695-b058-6fcbdbf21684</td>\n",
       "      <td>0.462976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49</td>\n",
       "      <td>0.115619</td>\n",
       "      <td>dart</td>\n",
       "      <td>0.637333</td>\n",
       "      <td>60173</td>\n",
       "      <td>44</td>\n",
       "      <td>0.354967</td>\n",
       "      <td>0.285429</td>\n",
       "      <td>0.983128</td>\n",
       "      <td>a4851af4-ed57-4a3c-9828-9d9fc887655a</td>\n",
       "      <td>0.455598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>49</td>\n",
       "      <td>0.115797</td>\n",
       "      <td>dart</td>\n",
       "      <td>0.595130</td>\n",
       "      <td>60378</td>\n",
       "      <td>44</td>\n",
       "      <td>0.353974</td>\n",
       "      <td>0.610409</td>\n",
       "      <td>0.984347</td>\n",
       "      <td>067e8a88-fbfc-4d57-b9c8-1cdcecc76b48</td>\n",
       "      <td>0.453960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>49</td>\n",
       "      <td>0.114474</td>\n",
       "      <td>dart</td>\n",
       "      <td>0.629987</td>\n",
       "      <td>2557</td>\n",
       "      <td>44</td>\n",
       "      <td>0.431246</td>\n",
       "      <td>0.608502</td>\n",
       "      <td>0.984347</td>\n",
       "      <td>22d3235a-d529-471f-ba51-231bec471d9d</td>\n",
       "      <td>0.451359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>49</td>\n",
       "      <td>0.115619</td>\n",
       "      <td>dart</td>\n",
       "      <td>0.657001</td>\n",
       "      <td>60173</td>\n",
       "      <td>45</td>\n",
       "      <td>0.354967</td>\n",
       "      <td>0.285429</td>\n",
       "      <td>0.983128</td>\n",
       "      <td>33c3098d-5201-4e27-964d-9e3a3a47a96d</td>\n",
       "      <td>0.451220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_leaves  learning_rate boosting_type  subsample subsample_for_bin  \\\n",
       "42         49       0.115986          dart   0.629987             60611   \n",
       "32         49       0.115619          dart   0.637333             60173   \n",
       "33         49       0.115797          dart   0.595130             60378   \n",
       "67         49       0.114474          dart   0.629987              2557   \n",
       "11         49       0.115619          dart   0.657001             60173   \n",
       "\n",
       "   min_child_samples  reg_alpha  reg_lambda  colsample_bytree  \\\n",
       "42                44   0.353974    0.590491          0.984347   \n",
       "32                44   0.354967    0.285429          0.983128   \n",
       "33                44   0.353974    0.610409          0.984347   \n",
       "67                44   0.431246    0.608502          0.984347   \n",
       "11                45   0.354967    0.285429          0.983128   \n",
       "\n",
       "                               config_id     score  \n",
       "42  132dc8d6-bab1-4695-b058-6fcbdbf21684  0.462976  \n",
       "32  a4851af4-ed57-4a3c-9828-9d9fc887655a  0.455598  \n",
       "33  067e8a88-fbfc-4d57-b9c8-1cdcecc76b48  0.453960  \n",
       "67  22d3235a-d529-471f-ba51-231bec471d9d  0.451359  \n",
       "11  33c3098d-5201-4e27-964d-9e3a3a47a96d  0.451220  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.sort_values('score', ascending = False, inplace = True)\n",
    "config.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
